# üéì NIT Rourkela CS Department Chatbot

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Node](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg)
![Python](https://img.shields.io/badge/python-3.11%2B-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**An intelligent, RAG-powered conversational AI assistant for the Computer Science Department at NIT Rourkela**

[Features](#-features) ‚Ä¢ [Architecture](#-architecture) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üåü Overview

Welcome to the **NIT Rourkela CS Department Chatbot** ‚Äì a cutting-edge, conversational AI system built with modern technologies. This chatbot leverages **Retrieval-Augmented Generation (RAG)** to provide accurate, context-aware responses about faculty, courses, research areas, facilities, and more.

### Why This Chatbot?

- üéØ **Instant Information Access**: Get answers about specializations, faculty, courses, and research instantly
- üß† **Smart & Accurate**: RAG architecture ensures responses are grounded in actual department data
- üìö **Dynamic Knowledge Base**: Upload PDFs, DOCX, TXT files to continuously expand the knowledge base
- ‚ö° **Lightning Fast**: Optimized with TF-IDF embeddings and phi3:3.8b model for quick responses
- üîí **Privacy-First**: Runs entirely locally ‚Äì no data leaves your infrastructure

---

## ‚ú® Features

### ü§ñ Core Capabilities

| Feature | Description |
|---------|-------------|
| **Natural Language Queries** | Ask questions naturally: "Who teaches Machine Learning?" or "What are the M.Tech specializations?" |
| **Faculty Information** | Get details about faculty members, their research areas, publications, and courses |
| **Course Details** | Information about courses, prerequisites, syllabus, and instructors |
| **Research Areas** | Explore research domains, ongoing projects, and publications |
| **Facilities & Labs** | Learn about available labs, equipment, and research centers |
| **Document Upload** | Dynamically add new information via PDF, DOCX, TXT, or JSON files |

### üõ†Ô∏è Technical Highlights

- **Hybrid Architecture**: Node.js/TypeScript backend + Python microservice for AI/ML operations
- **Vector Database**: ChromaDB for efficient semantic search
- **Lightweight LLM**: Ollama with phi3:3.8b(2.2GB) ‚Äì perfect for MacBook Air
- **RAG Pipeline**: Retrieval-Augmented Generation ensures factual, grounded responses
- **TF-IDF Embeddings**: Fast, efficient text embeddings without GPU requirements
- **Type-Safe**: Full TypeScript implementation with Zod validation
- **Scalable Design**: Microservices architecture ready for production deployment

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (Optional)                       ‚îÇ
‚îÇ                  React / Next.js / Vue                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Node.js/Express/TypeScript Backend              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Routes     ‚îÇ  ‚îÇ Controllers  ‚îÇ  ‚îÇ  Middleware  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ                    ‚îÇ
            ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ChromaDB       ‚îÇ   ‚îÇ  Python Microservice    ‚îÇ
‚îÇ  Vector Store    ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                  ‚îÇ   ‚îÇ  ‚îÇ Ollama (Phi-3)   ‚îÇ   ‚îÇ
‚îÇ  - Embeddings    ‚îÇ   ‚îÇ  ‚îÇ LLM Generation   ‚îÇ   ‚îÇ
‚îÇ  - Semantic      ‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ    Search        ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ TF-IDF Embedder  ‚îÇ   ‚îÇ
                       ‚îÇ  ‚îÇ Text Processing  ‚îÇ   ‚îÇ
                       ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                       ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
                       ‚îÇ  ‚îÇ Doc Processors   ‚îÇ   ‚îÇ
                       ‚îÇ  ‚îÇ PDF/DOCX/TXT     ‚îÇ   ‚îÇ
                       ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Components

1. **Express Backend (Node.js/TypeScript)**
   - RESTful API endpoints
   - File upload handling
   - Request validation & error handling
   - Business logic orchestration

2. **Python Microservice**
   - Text embedding generation (TF-IDF)
   - LLM response generation (Ollama)
   - Document processing (PDF, DOCX, TXT)
   - Text chunking and preprocessing

3. **ChromaDB Vector Store**
   - Stores document embeddings
   - Performs similarity search
   - Retrieves relevant context

4. **Ollama + phi3:3.8b**
   - Lightweight language model
   - Context-aware response generation
   - Runs locally on CPU

---

## üöÄ Quick Start

### Prerequisites

Before you begin, ensure you have:

- **Node.js** >= 18.0.0 ([Download](https://nodejs.org/))
- **Python** 3.11+ ([Download](https://www.python.org/downloads/))
- **Ollama** ([Install Guide](https://ollama.ai/))
- **Git** ([Download](https://git-scm.com/))

### Installation

#### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/yourusername/nit-rourkela-cs-chatbot.git
cd nit-rourkela-cs-chatbot
```

#### 2Ô∏è‚É£ Install Ollama and Download phi3:3.8b

```bash
# Install Ollama (macOS)
brew install ollama

# Start Ollama service
ollama serve

# In a new terminal, pull phi3:3.8b model
ollama pull phi3:3.8b
```

#### 3Ô∏è‚É£ Setup Python Microservice

```bash
cd python_service

# Create virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate  # macOS/Linux
# OR
.\venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

cd ..
```

#### 4Ô∏è‚É£ Setup Node.js Backend

```bash
# Install dependencies
npm install

# Create environment file
cp .env.example .env

# Edit .env with your configuration (optional)
```

#### 5Ô∏è‚É£ Add Knowledge Base

Create your department data file:

```bash
# Create knowledge base directory
mkdir -p knowledge_base

# Add your department_data.json file
# (See knowledge_base/department_data.json.example)
```

---

## üéÆ Running the Application

### Option 1: Automated Start (Recommended)

```bash
chmod +x start-all.sh
./start-all.sh
```

### Option 2: Manual Start (3 Terminals)

**Terminal 1 - Ollama:**
```bash
ollama serve
```

**Terminal 2 - Python Service:**
```bash
cd python_service
source venv/bin/activate
python app.py
```

**Terminal 3 - Node.js Backend:**
```bash
npm run dev
```

The API will be available at: **http://localhost:8000**

---

## üìö API Documentation

### Base URL
```
http://localhost:8000/api/v1
```

### Endpoints

#### 1. Health Check
```http
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "services": {
    "python": "healthy",
    "vectorStore": "healthy"
  },
  "vectorStore": {
    "documentsCount": 150
  },
  "model": "phi3:3.8b"
}
```

#### 2. Query Chatbot
```http
POST /query
Content-Type: application/json

{
  "query": "What are the M.Tech specializations available?"
}
```

**Response:**
```json
{
  "answer": "The M.Tech program offers three specializations: 1) Artificial Intelligence and Machine Learning (AIML), 2) Data Science and Analytics (DSA), and 3) Cybersecurity (CS). Each specialization has 20 seats available.",
  "sources": [
    {
      "text": "specializations: [{ name: 'Artificial Intelligence and Machine Learning'...",
      "metadata": {
        "source": "knowledge_base",
        "type": "json",
        "category": "programs.mtech"
      }
    }
  ],
  "processingTime": 1523
}
```

#### 3. Upload Document
```http
POST /upload
Content-Type: multipart/form-data

file: [PDF/DOCX/TXT/JSON file]
```

**Response:**
```json
{
  "success": true,
  "message": "Document uploaded and processed successfully",
  "filename": "faculty_details.pdf",
  "chunksCreated": 45
}
```

#### 4. Load Knowledge Base
```http
POST /load-knowledge-base
```

**Response:**
```json
{
  "success": true,
  "message": "Knowledge base loaded successfully",
  "documentsLoaded": 150
}
```

#### 5. Get Statistics
```http
GET /stats
```

**Response:**
```json
{
  "success": true,
  "stats": {
    "count": 150
  }
}
```

#### 6. Clear Knowledge Base
```http
DELETE /knowledge-base
```

---

## üß™ Testing

### Using cURL

```bash
# Test health
curl http://localhost:8000/api/v1/health

# Load knowledge base
curl -X POST http://localhost:8000/api/v1/load-knowledge-base

# Query the chatbot
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Who teaches Machine Learning?"}'

# Upload a document
curl -X POST http://localhost:8000/api/v1/upload \
  -F "file=@/path/to/document.pdf"
```

### Example Queries

Try asking:
- "What are the research areas in the CS department?"
- "Who is Dr. Rajesh Kumar?"
- "List all faculty members specializing in AI"
- "What courses are offered in Cybersecurity?"
- "Tell me about the Data Science lab"
- "What is the placement record?"

---

## üìÅ Project Structure

```
nit-rourkela-cs-chatbot/
‚îú‚îÄ‚îÄ src/                          # Node.js/TypeScript source
‚îÇ   ‚îú‚îÄ‚îÄ config/                   # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ controllers/              # Route controllers
‚îÇ   ‚îú‚îÄ‚îÄ routes/                   # API routes
‚îÇ   ‚îú‚îÄ‚îÄ services/                 # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vectorStore.ts        # ChromaDB integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pythonService.ts      # Python service client
‚îÇ   ‚îú‚îÄ‚îÄ middleware/               # Express middleware
‚îÇ   ‚îú‚îÄ‚îÄ types/                    # TypeScript types
‚îÇ   ‚îú‚îÄ‚îÄ app.ts                    # Express app setup
‚îÇ   ‚îî‚îÄ‚îÄ server.ts                 # Server entry point
‚îú‚îÄ‚îÄ python_service/               # Python microservice
‚îÇ   ‚îú‚îÄ‚îÄ venv/                     # Virtual environment
‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # Flask application
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ knowledge_base/               # Department data
‚îÇ   ‚îî‚îÄ‚îÄ department_data.json      # Main knowledge base
‚îú‚îÄ‚îÄ uploads/                      # Uploaded documents
‚îú‚îÄ‚îÄ chroma_db/                    # ChromaDB storage
‚îú‚îÄ‚îÄ .env                          # Environment variables
‚îú‚îÄ‚îÄ package.json                  # Node.js dependencies
‚îú‚îÄ‚îÄ tsconfig.json                 # TypeScript configuration
‚îú‚îÄ‚îÄ start-all.sh                  # Startup script
‚îî‚îÄ‚îÄ README.md                     # This file
```

---

## ‚öôÔ∏è Configuration

### Environment Variables

Create a `.env` file in the root directory:

```env
# Server Configuration
NODE_ENV=development
PORT=8000

# Service URLs
PYTHON_SERVICE_URL=http://localhost:5001

# Paths
UPLOAD_DIR=./uploads
KNOWLEDGE_BASE_DIR=./knowledge_base
CHROMA_DB_PATH=./chroma_db

# Ollama Configuration
OLLAMA_MODEL=phi3:3.8b
OLLAMA_BASE_URL=http://localhost:11434

# Vector Store Settings
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RESULTS=5
EMBEDDING_MODEL=TF-IDF
```

---

## üéØ Use Cases

### For Students
- Quick access to course information and prerequisites
- Find faculty expertise for project guidance
- Learn about available specializations and research areas
- Get information about labs and facilities

### For Faculty
- Share updated research information
- Provide course details and syllabi
- Announce office hours and availability

### For Administrators
- Maintain up-to-date department information
- Handle routine queries automatically
- Reduce administrative workload

### For Prospective Students
- Learn about programs and specializations
- Understand admission requirements
- Explore research opportunities

---

## üöÄ Deployment

### Docker (Coming Soon)

```bash
docker-compose up -d
```

### PM2 (Production)

```bash
# Build TypeScript
npm run build

# Start with PM2
pm2 start ecosystem.config.js
```

### Cloud Deployment

The chatbot can be deployed on:
- **AWS**: EC2, ECS, or Lambda
- **Google Cloud**: Compute Engine or Cloud Run
- **Azure**: Virtual Machines or Container Instances
- **DigitalOcean**: Droplets or App Platform

---

## üîÆ Roadmap

- [ ] Frontend web interface (React)
- [ ] User authentication and session management
- [ ] Conversation history and memory
- [ ] Multi-language support
- [ ] Voice input/output
- [ ] Admin dashboard for knowledge base management
- [ ] Analytics and usage statistics
- [ ] Integration with department website
- [ ] Mobile application (Flutter/React Native)
- [ ] Advanced semantic search with sentence-transformers

---

## ü§ù Contributing

We welcome contributions! Please follow these steps:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Contribution Guidelines

- Follow TypeScript/Python best practices
- Add tests for new features
- Update documentation
- Ensure code passes linting
- Write clear commit messages

---

## üêõ Troubleshooting

### Common Issues

**1. Ollama not responding**
```bash
# Check if Ollama is running
ps aux | grep ollama

# Restart Ollama
killall ollama
ollama serve
```

**2. Python service fails to start**
```bash
# Check Python version
python3 --version  # Should be 3.11+

# Reinstall dependencies
cd python_service
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

**3. ChromaDB errors**
```bash
# Clear ChromaDB database
rm -rf chroma_db
mkdir chroma_db
```

**4. Port already in use**
```bash
# Find process using port 8000
lsof -i :8000

# Kill the process
kill -9 <PID>
```

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üë• Authors

**Sayak Bhattacharya**
- M.Tech Computer Science Engineering
- National Institute of Technology Rourkela
- GitHub: [@yourusername](https://github.com/yourusername)

---

## üôè Acknowledgments

- **NIT Rourkela CS Department** for the inspiration
- **Ollama** for the amazing local LLM infrastructure
- **ChromaDB** for the efficient vector database
- **Anthropic** for Claude assistance in development
- Open-source community for the incredible tools

---

## üìû Support

Having issues? Need help?

- üìß Email: sayak6237@gmail.com
- üêõ Issues: [GitHub Issues](https://github.com/flash6083/rag_llm_chatbot/issues)
- üí¨ Discussions: [GitHub Discussions](https://github.com/flash6083/rag_llm_chatbot/discussions)

---

<div align="center">

**Made with ‚ù§Ô∏è at NIT Rourkela**

‚≠ê Star this repo if you find it helpful!

[Back to Top](#-nit-rourkela-cs-department-chatbot)

</div>
